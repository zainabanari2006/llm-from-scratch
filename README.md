# LLMs-from-Scratch 🧠🚀

This project is based on the [rasbt/LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch) tutorials. It is a hands-on implementation of a *ChatGPT-like language model* using *PyTorch*, built step-by-step from zero.

---

## 📌 About the Project

This repository contains notebooks that explain and build:

- The Transformer architecture
- Positional encoding
- Multi-head self-attention
- Tokenization and embeddings
- Mini LLM training loop

This project is aimed at learning *Natural Language Processing (NLP)* fundamentals and understanding how modern LLMs (Large Language Models) are designed.

---

## 🔧 Tech Stack

- Python 3.10+
- PyTorch
- Jupyter Notebook
- NumPy, Matplotlib
- tqdm

---

## 📁 Notebooks Included

| Notebook | Description |
|----------|-------------|
| 01_transformer_architecture_from_scratch.ipynb | Building blocks of a Transformer |
| 02_positional_encoding.ipynb | Adding position context |
| 03_attention_mechanism.ipynb | Implementing self-attention |
| 04_mini_llm_training_loop.ipynb | Training a basic LLM |

More coming soon!

---

## 🚀 How to Run

```bash
# Clone the repo
git clone https://github.com/zainabanari2006/llm-from-scratch.git
cd llm-from-scratch

# Set up virtual environment (optional but recommended)
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate (Windows)

# Install dependencies
pip install -r requirements.txt

# Launch Jupyter
jupyter notebook
---

## 💡 Learning Goal

This project is part of my journey into Artificial Intelligence, NLP, and understanding how modern AI tools like ChatGPT are built — from scratch.

> 🌟 Built with love, code, and curiosity by [Zainab Ansari](https://github.com/zainabanari2006)

---

## 🪪 License

This project is licensed under the MIT License.
